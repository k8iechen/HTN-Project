{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "# things we need for NLP\n",
    "import nltk\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer = LancasterStemmer()\n",
    "\n",
    "# things we need for Tensorflow\n",
    "import numpy as np\n",
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import re\n",
    "import unicodedata\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore all of our data structures\n",
    "import pickle\n",
    "data = pickle.load( open( \"training_data\", \"rb\" ) )\n",
    "words = data['words']\n",
    "classes = data['classes']\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "classes_details = data['classes_details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import urllib.response\n",
    "import sys\n",
    "import os, glob\n",
    "import http.client, urllib\n",
    "import json\n",
    "import http.client, urllib.request, urllib.parse, urllib.error, base64\n",
    "\n",
    "# Replace the accessKey string value with your valid access key.\n",
    "accessKey = '82e4612615634c398bfd26e7d6327833'\n",
    "url = 'westcentralus.api.cognitive.microsoft.com'\n",
    "path = '/text/analytics/v2.0/keyPhrases'\n",
    "\n",
    "def extract_keywords(body):\n",
    "    headers = {'Ocp-Apim-Subscription-Key': accessKey}\n",
    "    conn = http.client.HTTPSConnection(url)\n",
    "    body_req = {'documents':[{'language': 'en', 'id': 1, 'text': body}]}\n",
    "    body_json = json.dumps(body_req)\n",
    "    conn.request (\"POST\", path, body_json, headers)\n",
    "    response = conn.getresponse ()\n",
    "    string = response.read().decode('utf-8')\n",
    "    json_obj = json.loads(string)\n",
    "    print(\"json_obj: \", json_obj)\n",
    "    keyphrases_list = ((json_obj['documents'])[0])['keyPhrases']\n",
    "    print(\"keyphrases_list: \", keyphrases_list)\n",
    "    return keyphrases_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\steven\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tflearn\\objectives.py:66: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(train_x[0])])\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, 8)\n",
    "net = tflearn.fully_connected(net, len(train_y[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    "\n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## a table structure to hold the different punctuation used\n",
    "tbl = dict.fromkeys(i for i in range(sys.maxunicode)\n",
    "                    if unicodedata.category(chr(i)).startswith('P'))\n",
    "\n",
    "## method to remove punctuations from sentences.\n",
    "def remove_punctuation(text):\n",
    "     return text.translate(tbl)\n",
    "\n",
    "def clean_up_sentence(sentence):\n",
    "    #strip punctuations, numbers, and words containing numbers\n",
    "    no_punct = remove_punctuation(sentence)\n",
    "    no_nums1 = ' '.join(s for s in no_punct.split() if not any(c.isdigit() for c in s))\n",
    "    no_nums2 = re.sub(r'\\d+', '', no_nums1)\n",
    "    keywords = extract_keywords(no_nums2)\n",
    "    keyword_str = ' '.join(s for s in keywords)\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(keyword_str)\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    print(\"sentence after stemming: \", sentence_words)\n",
    "    return sentence_words\n",
    "\n",
    "# return bag of words array: 0 or 1 for each word in the bag that exists in the sentence\n",
    "def bow(sentence, words, show_details=False):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = clean_up_sentence(sentence)\n",
    "    # bag of words\n",
    "    bag = [0]*len(words)  \n",
    "    for s in sentence_words:\n",
    "        for i,w in enumerate(words):\n",
    "            if s in w.strip().split(): \n",
    "                bag[i] = 1\n",
    "                if show_details:\n",
    "                    print (\"found in bag: %s\" % w)\n",
    "\n",
    "    return(np.array(bag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_obj:  {'documents': [{'id': '1', 'keyPhrases': ['stuffy nose', 'throat', 'days', 'sneezing', 'severe cough']}], 'errors': []}\n",
      "keyphrases_list:  ['stuffy nose', 'throat', 'days', 'sneezing', 'severe cough']\n",
      "sentence after stemming:  ['stuffy', 'nos', 'throat', 'day', 'sneez', 'sev', 'cough']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "['Acute Headache', 'Allergies', 'Alzheimer', 'Avian Influenza', 'Breast Cancer', 'Chickenpox', 'Chlamydia', 'Chronic Headache', 'Common Cold', 'Conjunctivitis', 'Coronary Heart Disease', \"Crohn's Disease\", 'Dermatitis', 'E Coli Infection', 'Eating Disorders including Anorexia & Bulimia Nervosa', 'HBV;Liver infection', 'Hepatitis B', 'Influenza', 'Intestinal Gas', 'Irritable Bowel Syndrome (IBS)', 'Nausea and Vomiting', 'Pregrancy', 'Prostate Cancer', 'Sleep Apnea', 'Stroke', 'Swine Influenza', 'West Nile Virus', 'Zika Virus']\n"
     ]
    }
   ],
   "source": [
    "p = bow(\"I have recently had a very runny and stuffy nose. The last few days, my throat has also been very sore and I have also developed a severe cough with lots of sneezing\", words)\n",
    "print (p)\n",
    "print (classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Steven\\Documents\\HTN PROJECT 2\\model.tflearn\n"
     ]
    }
   ],
   "source": [
    "# load our saved model\n",
    "model.load('./model.tflearn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ERROR_THRESHOLD = 0.01\n",
    "def classify(sentence):\n",
    "    # generate probabilities from the model\n",
    "    results = model.predict([bow(sentence, words)])[0]\n",
    "    #print(results)\n",
    "    # filter out predictions below a threshold\n",
    "    results = [[i,r] for i,r in enumerate(results) if r>ERROR_THRESHOLD]\n",
    "    # sort by strength of probability\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return_list = []\n",
    "    for r in results:\n",
    "        return_list.append((classes[r[0]], r[1]))\n",
    "    # return tuple of intent and probability\n",
    "    return return_list\n",
    "\n",
    "def more_response(key):\n",
    "    if key in [\"yes\", \"of course\", \"sure\", \"certainly\", \"absolutely\", \"yeah\", \"yep\", \"yup\", \"ya\", \"yea\", \"aye\"]:\n",
    "        sentence_new = input(\"Okay, please tell me any possible symptoms. The more details, the better!\")\n",
    "        return response(sentence_new,0)\n",
    "    elif key in [\"negative\", \"nope\", \"no\", \"nah\", \"no way\", \"nay\"]:\n",
    "        return print(\"Okay, thanks for visiting iDoctor. Enjoy the rest of your day!\")\n",
    "    else:\n",
    "        more = input(\"Sorry, I couldn't understand that. Would you like more diagnosis?\")\n",
    "        return more_response(more.strip().lower())\n",
    "\n",
    "def response(sentence, counter):\n",
    "    if counter <= 2:\n",
    "        results = classify(sentence)\n",
    "    # if we have a classification then find the matching intent tag\n",
    "        #if results and len(sentence) >= 10:\n",
    "            # loop as long as there are matches to process\n",
    "            #print(\"Here are some likely conditions you may have:\\n\")\n",
    "            #for i in range(0,min(3,len(results))):\n",
    "                #print((results[i])[0] + \": \" + classes_details[(results[i])[0]])\n",
    "           # more = input(\"Is there anything else you would like me to diagnose?\")\n",
    "            #return more_response(more.strip().lower())\n",
    "#         else:\n",
    "#             counter += 1\n",
    "#             sentence_add = input(\"Unfortunately, I do not have enough information. Please tell me more!\")\n",
    "#             sentence = sentence + \" \" + sentence_add\n",
    "#             print(\"SENTENCE UP UNTIL THIS POINT: \" + sentence)\n",
    "#             return response(sentence, counter)\n",
    "    else:\n",
    "        total_responses = \"\"\n",
    "        return print(\"Unfortunately, I cannot help diagnose your medical condition. Please consult a medical professional such as your family doctor. Enjoy the rest of your day!\")\n",
    "\n",
    "def main():\n",
    "    print(\"Hi there, my name is iDoctor. Today I will be helping to diagnose any possible medical conditions you may have. Let's get started!\")\n",
    "    name = input(\"Firstly, what is your name?\")\n",
    "    sentence = input(\"Hi \" + name + \"! Please tell me how you are feeling, and any possible symptoms you may be experiencing. The more details, the better!\")\n",
    "    response(sentence, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "json_obj:  {'documents': [{'id': '1', 'keyPhrases': ['stuffy nose', 'throat', 'days', 'body', 'severe cough', 'aches', 'congestion']}], 'errors': []}\n",
      "keyphrases_list:  ['stuffy nose', 'throat', 'days', 'body', 'severe cough', 'aches', 'congestion']\n",
      "sentence after stemming:  ['stuffy', 'nos', 'throat', 'day', 'body', 'sev', 'cough', 'ach', 'congest']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Common Cold', 0.533916),\n",
       " ('Influenza', 0.10738216),\n",
       " ('Swine Influenza', 0.08816636),\n",
       " ('Zika Virus', 0.07071872),\n",
       " ('Alzheimer', 0.032626472),\n",
       " ('Hepatitis B', 0.027823763),\n",
       " ('Avian Influenza', 0.027369391),\n",
       " ('Conjunctivitis', 0.02433819),\n",
       " ('Stroke', 0.014428946),\n",
       " ('Coronary Heart Disease', 0.012360531),\n",
       " ('Breast Cancer', 0.010235207)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify(\"I have recently had a very runny and stuffy nose. The last few days, my throat has also been very sore and I have also developed a severe cough with lots of sneezing. I have also gotten aches all over my body as well as congestion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "response() missing 1 required positional argument: 'counter'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-df384c5992ad>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i have a fever, arthralgia, and a rash on my arm\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: response() missing 1 required positional argument: 'counter'"
     ]
    }
   ],
   "source": [
    "response(\"i have a fever, arthralgia, and a rash on my arm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
